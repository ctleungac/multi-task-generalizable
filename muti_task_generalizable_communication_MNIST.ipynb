{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import ssl\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a73d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 200\n",
    "\n",
    "# training SNR\n",
    "channel_snr = 15 # in dB\n",
    "channel_type = 'awgn' # \"fading\" or \"awgn\"\n",
    "power_normalization = 'average' # \" average\" or \"max\" power constraint\n",
    "\n",
    "# ##### KSG MI estimator #######################\n",
    "# settings = {'kraskov_k': 3}\n",
    "# gpu_est = est.OpenCLKraskovMI(settings = settings)\n",
    "# # usage: MI = estimator.estimate(var1, var2)\n",
    "\n",
    "##### setting for communication channel ######\n",
    "\n",
    "def getnoisevariance(SNRdB,P=1):\n",
    "    snr = 10.0**(SNRdB/10.0)\n",
    "    N0 = P/snr\n",
    "    return (N0/2)\n",
    "\n",
    "noise_var = getnoisevariance(channel_snr,P=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = (x_train / 255.0)\n",
    "x_test = (x_test / 255.0)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label selection for phase 1\n",
    "# only half of the label will be selected \n",
    "##############################################\n",
    "\n",
    "label_permutation = np.arange(10) # fixed the chosen label\n",
    "# label_permutation = np.random.permutation(10) # random permutation\n",
    "LABEL_FIRST_HALF = label_permutation[:5]\n",
    "label2_list = np.zeros((6,5))\n",
    "for i in range(6):\n",
    "    label2_list[i][:] = label_permutation[i:i+5]\n",
    "\n",
    "train_filter = np.where(np.in1d(y_train, LABEL_FIRST_HALF))\n",
    "test_filter =  np.where(np.in1d(y_test, LABEL_FIRST_HALF))\n",
    "\n",
    "x_1train = x_train[train_filter]\n",
    "Y_1train = Y_train[train_filter]\n",
    "x_1test = x_test[test_filter]\n",
    "Y_1test = Y_test[test_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalized Input before \n",
    "# class GaussianNoiseLayer(layers.Layer):\n",
    "#     def __init__(self, stddev, **kwargs):\n",
    "#         super(GaussianNoiseLayer, self).__init__(**kwargs)\n",
    "#         self.stddev = stddev\n",
    "    \n",
    "#     def call(self, inputs, training=None):\n",
    "#         if training:\n",
    "#             noise = tf.random.normal(shape=tf.shape(inputs), mean=0.0, stddev=self.stddev)\n",
    "#             return inputs + noise\n",
    "#         else:\n",
    "#             noise = tf.random.normal(shape=tf.shape(inputs), mean=0.0, stddev=self.stddev)\n",
    "#             return inputs + noise\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         config = super(GaussianNoiseLayer, self).get_config()\n",
    "#         config.update({'noise_var': self.stddev})\n",
    "#         return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc384bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fading channel\n",
    "\n",
    "def fading(x, stddev, h=None):\n",
    "    \"\"\"Implements the fading channel with multiplicative fading and\n",
    "    additive white gaussian noise.\n",
    "    Args:\n",
    "        x: channel input symbols\n",
    "        stddev: standard deviation of noise\n",
    "    Returns:\n",
    "        y: noisy channel output symbols\n",
    "    \"\"\"\n",
    "    # channel gain\n",
    "    if h is None:\n",
    "        h = tf.complex(\n",
    "            tf.random.normal([tf.shape(x)[0], 1], 0, 1 / np.sqrt(2)),\n",
    "            tf.random.normal([tf.shape(x)[0], 1], 0, 1 / np.sqrt(2)),\n",
    "        )\n",
    "\n",
    "    # additive white gaussian noise\n",
    "    awgn = tf.complex(\n",
    "        tf.random.normal(tf.shape(x), 0, 1 / np.sqrt(2)),\n",
    "        tf.random.normal(tf.shape(x), 0, 1 / np.sqrt(2)),\n",
    "    )\n",
    "\n",
    "    return (h * x + stddev * awgn), h\n",
    "\n",
    "class Channel(layers.Layer):\n",
    "\n",
    "    def __init__(self, channel_type, channel_snr, power_normalization=\"average\", name=\"channel\", **kwargs):\n",
    "        super(Channel, self).__init__(name=name, **kwargs)\n",
    "        self.channel_type = channel_type\n",
    "        self.channel_snr = channel_snr\n",
    "        self.power_normalization = power_normalization\n",
    "\n",
    "    def call(self, inputs):\n",
    "        (encoded_img, prev_h) = inputs\n",
    "        inter_shape = tf.shape(encoded_img)\n",
    "        # reshape array to [-1, dim_z]\n",
    "        z = layers.Flatten()(encoded_img)\n",
    "        # convert from snr to std\n",
    "        # print(\"channel_snr: {}\".format(self.channel_snr))\n",
    "        noise_stddev = np.sqrt(10 ** (-self.channel_snr / 10))\n",
    "\n",
    "        # Add channel noise\n",
    "        if self.channel_type == \"awgn\":\n",
    "            dim_z = tf.shape(z)[1]\n",
    "            # normalize latent vector so that the average power is 1\n",
    "            if self.power_normalization == \"max\":\n",
    "                z_in = tf.tanh(z)\n",
    "            elif self.power_normalization == \"average\":\n",
    "                z_in = tf.sqrt(tf.cast(dim_z, dtype=tf.float32)) * tf.nn.l2_normalize(\n",
    "                    z, axis=1)\n",
    "            z_out = real_awgn(z_in, noise_stddev)\n",
    "            h = tf.ones_like(z_in)  # h just makes sense on fading channels\n",
    "\n",
    "        elif self.channel_type == \"fading\":\n",
    "            dim_z = tf.shape(z)[1] // 2\n",
    "            # convert z to complex representation\n",
    "            z_in = tf.complex(z[:, :dim_z], z[:, dim_z:])\n",
    "            # normalize the latent vector so that the average power is 1\n",
    "            z_norm = tf.reduce_sum(\n",
    "                tf.math.real(z_in * tf.math.conj(z_in)), axis=1, keepdims=True\n",
    "            )\n",
    "            z_in = z_in * tf.complex(\n",
    "                tf.sqrt(tf.cast(dim_z, dtype=tf.float32) / z_norm), 0.0\n",
    "            )\n",
    "            z_out, h = fading(z_in, noise_stddev, prev_h)\n",
    "            # convert back to real\n",
    "            z_out = tf.concat([tf.math.real(z_out), tf.math.imag(z_out)], 1)\n",
    "\n",
    "        # convert signal back to intermediate shape\n",
    "        z_out = tf.reshape(z_out, inter_shape)\n",
    "\n",
    "        return z_out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### custom callback function for MI calculation\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def normalize_data_new(data,C):\n",
    "    data = np.reshape(data, (data.shape[0],int(data.size/data.shape[0])))\n",
    "    means =  np.tile(np.mean(data,axis=0),(data.shape[0],1))\n",
    "    data = data - means\n",
    "    sqz = data**2\n",
    "    norm =  np.sqrt(np.mean(np.sum(sqz,axis=1)))\n",
    "    normalized_data = C*data / norm\n",
    "    \n",
    "    return normalized_data,norm**2\n",
    "class getMIOutput(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, trn, tst, snr, num_selection, embedding_network, do_save_func=None, *kargs, **kwargs):\n",
    "        super(getMIOutput, self).__init__(*kargs, **kwargs)\n",
    "        self.layer_values = []\n",
    "        self.trn = trn\n",
    "        self.tst = tst\n",
    "        self.snr = snr\n",
    "        self.datalist = []\n",
    "        self.num_selection = num_selection\n",
    "        self.embedding_network = embedding_network\n",
    "        self.do_save_func = do_save_func\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.layer_values = []\n",
    "        self.layerixs = []\n",
    "        self.layerfuncs = []\n",
    "\n",
    "        # Assuming the embedding layer index is 3, change it based on the actual index\n",
    "        embedding_layer_index = 3\n",
    "\n",
    "        for lndx, l in enumerate(self.embedding_network.layers):\n",
    "            self.layerixs.append(lndx)\n",
    "            self.layer_values.append(lndx)\n",
    "            self.layerfuncs.append(K.function(self.embedding_network.inputs, [l.output,]))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.do_save_func is not None and not self.do_save_func(epoch):\n",
    "            return\n",
    "        \n",
    "        data = {\n",
    "            'activity_tst': []    # Activity in each layer for the test set\n",
    "        }\n",
    "\n",
    "        for lndx, layerix in enumerate(self.layerixs):\n",
    "            #if (lndx == 4):  # Assuming you want to access a specific layer\n",
    "            data['activity_tst'].append(self.layerfuncs[lndx]([self.trn[:self.num_selection],])[0])\n",
    "\n",
    "        save_dic = {'epoch': epoch, 'data': data}\n",
    "        self.datalist.append(save_dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_report(epoch):\n",
    "#     if epoch < 20:       # Log for all first 20 epochs\n",
    "#         return True\n",
    "    if epoch < 100:    # Then for every 5th epoch\n",
    "        return (epoch % 5 == 0)\n",
    "    elif epoch < 200:    # Then every 10th\n",
    "        return (epoch % 10 == 0)\n",
    "    else:                # Then every 100th\n",
    "        return (epoch % 100 == 0)\n",
    "    \n",
    "    \n",
    "def train_first_stage(lambda_val):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    prev_chn_gain = None\n",
    "\n",
    "        ############ Model Structure ###############################\n",
    "\n",
    "    input_layer  = tf.keras.layers.Input((x_train.shape[1],))\n",
    "    encoder_1 = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
    "    encoder_2 =  tf.keras.layers.Dense(40, activation='relu')(encoder_1)\n",
    "    ## first loss: classification \n",
    "    normalized_x = tf.keras.layers.Lambda(lambda x: K.tanh(x))(encoder_2)\n",
    "    fadingchannel = Channel(channel_type, channel_snr, name=\"channel_output\")\n",
    "    noise_layer, chn_gain = fadingchannel((normalized_x, prev_chn_gain))\n",
    "\n",
    "    CE_decoder_1 = tf.keras.layers.Dense(40, activation='relu')(noise_layer)\n",
    "    CE_decoder_2 = tf.keras.layers.Dense(40, activation='relu')(CE_decoder_1)\n",
    "    CE_output = tf.keras.layers.Dense(10,activation = 'softmax',name='CE')(CE_decoder_2)\n",
    "\n",
    "    ## second loss: reconstruction\n",
    "    mse_decoder_1 = tf.keras.layers.Dense(256, activation='relu')(noise_layer)\n",
    "    mse_output = tf.keras.layers.Dense(x_train.shape[1],activation = 'sigmoid',name='mse')(mse_decoder_1) \n",
    "    \n",
    "    model = tf.keras.Model(inputs = input_layer, outputs = [CE_output,mse_output])\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=5e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.8)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss = {'CE' : 'categorical_crossentropy', \n",
    "                          'mse' : 'mse'},\n",
    "                  metrics = {'CE' : 'accuracy', \n",
    "                             'mse': tf.keras.metrics.RootMeanSquaredError()},\n",
    "                  loss_weights=[1, lambda_val])\n",
    "\n",
    "    #     reporter = getMIOutput(trn=x_1train, \n",
    "    #                                tst=x_1test, \n",
    "    #                                snr=channel_snr,\n",
    "    #                               do_save_func=do_report)\n",
    "\n",
    "    history = model.fit(x=x_1train, y=(Y_1train,x_1train),\n",
    "                        batch_size=128,\n",
    "                        epochs=150,\n",
    "                        verbose=0,\n",
    "                        validation_data=(x_1test, (Y_1test,x_1test)))\n",
    "                       #callbacks = [callback])\n",
    "                        #callbacks=[reporter,])\n",
    "    print(\"acc:\", history.history['val_CE_accuracy'][-1]) \n",
    "\n",
    "\n",
    "#     ep_last = len(reporter.datalist) -1\n",
    "#     # Z_data = reporter.datalist[EPOCH]['data']['activity_tst'][3][:10000]\n",
    "#     ZHAT_data = reporter.datalist[ep_last]['data']['activity_tst'][4][:SAMPLE_NUM]\n",
    "#     x_selected = funcs.normalize_data_new(x_1train[:SAMPLE_NUM],C=10)[0]\n",
    "#     print(\"Current I(Z_hat; X) is: \",gpu_est.estimate(funcs.normalize_data_new(ZHAT_data,C=4)[0],x_selected))\n",
    "\n",
    "  \n",
    "    ################### secpmd stage #################\n",
    "    print(\"stage 2!\")\n",
    "   \n",
    "    train_filter = np.where(np.in1d(y_train, LABEL_SECOND_HALF))\n",
    "    test_filter =  np.where(np.in1d(y_test, LABEL_SECOND_HALF))\n",
    "\n",
    "    x_retrain = x_train[train_filter]\n",
    "    x_retest = x_test[test_filter]\n",
    "    Y_retrain = Y_train[train_filter]\n",
    "    Y_retest = Y_test[test_filter]\n",
    "\n",
    "    CE_dense_3 = layers.Dense(40, activation='relu')(noise_layer)\n",
    "    CE_dense_3 = layers.Dense(40, activation='relu')(CE_dense_3)\n",
    "    CE_output1 = tf.keras.layers.Dense(10,activation = 'softmax',name='CE')(CE_dense_3)\n",
    "\n",
    "    reconstructed_model = tf.keras.models.Model(inputs = input_layer, outputs = [CE_output1,mse_output])\n",
    "\n",
    "    reconstructed_model.layers[1].trainable = False\n",
    "    reconstructed_model.layers[2].trainable = False\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=2e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.8)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    reconstructed_model.compile(optimizer=opt, \n",
    "                loss = {'CE' : 'categorical_crossentropy', \n",
    "                          'mse' : 'mse'\n",
    "                         },              loss_weights=[1, 0],\n",
    "                  metrics = {'CE' : 'accuracy', \n",
    "                             'mse': tf.keras.metrics.RootMeanSquaredError()\n",
    "                           }\n",
    "                 )\n",
    "\n",
    "    #     reporter_2 = getMIOutput(trn=x_retrain, \n",
    "    #                                tst=Y_retrain, \n",
    "    #                                snr=channel_snr,\n",
    "    #                               do_save_func=do_report)\n",
    "\n",
    "    history1 = reconstructed_model.fit(x=x_retrain, y=(Y_retrain,x_retrain),\n",
    "                        batch_size=256,\n",
    "                        epochs=50,\n",
    "                        verbose=0,\n",
    "                        validation_data=(x_retest, (Y_retest,x_retest)))\n",
    "                        # callbacks=[callback])\n",
    "    results = reconstructed_model.evaluate(x = x_retest, y = (Y_retest,x_retest))\n",
    "    print(\"test accuracy for phase 2: \", history1.history['val_CE_accuracy'][-1]) \n",
    "    return history.history['val_CE_accuracy'][-1], history1.history['val_CE_accuracy'][-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4bff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd = np.sqrt(noise_var)\n",
    "\n",
    "lambda_list = [0,1,3,10]\n",
    "acc1_list = []\n",
    "acc2_list = []\n",
    "for i in range(6):\n",
    "    print(\"current overlap is: \", (i) )\n",
    "    LABEL_SECOND_HALF = label2_list[5-i]\n",
    "    for lambda_val in lambda_list:\n",
    "        print(\"lambda: \",lambda_val)\n",
    "        acc1, acc2 = train_first_stage(lambda_val) \n",
    "        acc1_list.append(acc1) # accuracy for phase 1\n",
    "        acc2_list.append(acc2) # accuracy for phase 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
